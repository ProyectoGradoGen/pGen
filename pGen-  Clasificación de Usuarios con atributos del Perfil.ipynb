{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexion a base de datos para btener los usuarios que tenemos guardados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Conexión a la base de datos\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "client = MongoClient(\"localhost\",27017)\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"proyectodb\"]\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Consumo del servicio de Twitter\n",
    "import tweepy\n",
    "auth = tweepy.OAuthHandler('n5Vo0aNUy4l2eu52cwJicUJ33', 'guPfeOe6axjD9uOeSLLGC8IfClswpiLX5tHafdNNtn4FErKmPi')\n",
    "auth.set_access_token('784154913454645248-HefUzw6JOeMibIRLsNNu7hESr77wzCy', 'BHtr8sJrbwhbUapFE4NtsHL3OncTJ4etAaUydKOktWLV3')\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Colecciones de la base de datos\n",
    "listaMujeresTest = api.list_members(slug='JimesMujeres',owner_screen_name='@jimesproject', count=2000)\n",
    "listaHombresTest = api.list_members(slug='JimesHombres',owner_screen_name='@jimesproject', count=2000)\n",
    "\n",
    "\n",
    "collHombres= db.usuarios_hombres.find();\n",
    "\n",
    "collMujeres= db.usuarios_mujeres.find();\n",
    "\n",
    "collHombresConcat = db['tweets_hombres_concat_url_cambiada']\n",
    "\n",
    "collMujeresConcat = db['tweets_mujeres_concat_url_cambiada']\n",
    "\n",
    "collHombresConcatNuestros = db['tweets_hombres_concat_nuestros']\n",
    "\n",
    "collMujeresConcatNuestros = db['tweets_mujeres_concat_nuestros']\n",
    "\n",
    "collHombresFind = db['usuarios_hombres']\n",
    "\n",
    "collMujeresFind = db['usuarios_mujeres']\n",
    "\n",
    "collFotoPerfilHombres = db['foto_perfil_hombres']\n",
    "\n",
    "collFotoPerfilMujeres = db['foto_perfil_mujeres']\n",
    "\n",
    "collFotoPerfilHombresNuestro = db['foto_perfil_hombres_nuestro']\n",
    "\n",
    "collFotoPerfilMujeresNuestro = db['foto_perfil_mujeres_nuestro']\n",
    "\n",
    "collEmojisHombres = db['emojis_hombres']\n",
    "\n",
    "collEmojisMujeres = db['emojis_mujeres']\n",
    "\n",
    "collEmojisHombresNuestros = db['emojis_hombres_nuestros']\n",
    "\n",
    "collEmojisMujeresNuestros = db['emojis_mujeres_nuestros']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Punteros auxiliares para las colecciones\n",
    "collHombresAuxN = collHombres\n",
    "\n",
    "collMujeresAuxN = collMujeres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usuarios de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Armamos lista de usuarios\n",
    "US_train = []\n",
    "vClasifUs = []\n",
    "for i in range(0,7000):\n",
    "    try:\n",
    "        US_train = US_train + [collHombresAux[i]['screen_name']]\n",
    "        vClasifUs = vClasifUs + [0]\n",
    "        US_train = US_train + [collMujeresAux[i]['screen_name']]\n",
    "        vClasifUs = vClasifUs + [1]\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividimos el conjunto de usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Librerias\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics   \n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reducción de atributos para cada clasificador\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizerLinear1 = TfidfVectorizer(max_df=0.6)\n",
    "vectorizerNB1 = TfidfVectorizer(min_df=0.01)\n",
    "vectorizerDT_Kmeans = TfidfVectorizer(max_df=0.5,min_df=0.05)\n",
    "vectorizerMLP1 = TfidfVectorizer(max_df=0.5, min_df=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se dividen los tweets y se agrega la descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Usuarios de entrenamiento\n",
    "X_tweetsTrain = []\n",
    "X_tweetsTest = []\n",
    "y_vClasifTweetsTrain = vClasifUs\n",
    "\n",
    "for us in US_train:\n",
    "    try:   \n",
    "        cursor = collHombresConcat.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        cursorUsuario = collHombresFind.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() == 0:\n",
    "            cursor = collMujeresConcat.find({\"screen_name\":{\"$in\":[us]}})\n",
    "            cursorUsuario = collMujeresFind.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() > 1:\n",
    "            print(us)    \n",
    "        for s in cursor:\n",
    "            X_tweetsTrain = X_tweetsTrain + [s['text']  + cursorUsuario[0]['description']]        \n",
    "    except Exception as e:\n",
    "        print(e)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Usuarios de test\n",
    "US_test =[]\n",
    "y_vClasifTweetsTest=[]\n",
    "X_tweetsTest = []\n",
    "cont=0\n",
    "for i in range(0,161):\n",
    "    try:   \n",
    "        cursorH = collHombresConcatNuestros.find({\"screen_name\":{\"$in\":[listaHombresTest[i].screen_name]}})\n",
    "        US_test+=[listaHombresTest[i].screen_name]\n",
    "        \n",
    "        if(cursorH.count() == 0):\n",
    "            print(listaHombresTest[i].screen_name)\n",
    "        y_vClasifTweetsTest+=[0]\n",
    "        for s in cursorH:#aca siempre hay 1\n",
    "                X_tweetsTest = X_tweetsTest + [s['text'] + listaHombresTest[i].description] \n",
    "                cont+=1\n",
    "                \n",
    "                #print(i)\n",
    "        if (i < 79):\n",
    "            cursorM = collMujeresConcatNuestros.find({\"screen_name\":{\"$in\":[listaMujeresTest[i].screen_name]}})\n",
    "            if(cursorM.count() == 0):\n",
    "                print(listaMujeresTest[i].screen_name)\n",
    "            US_test+=[listaMujeresTest[i].screen_name]\n",
    "            y_vClasifTweetsTest+=[1]\n",
    "            for s in cursorM:#aca siempre hay 1\n",
    "                X_tweetsTest = X_tweetsTest + [s['text'] + listaMujeresTest[i].description] \n",
    "                cont+=1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformamos los tweets para entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vX_train = vectorizerLinear1.fit_transform(X_tweetsTrain)\n",
    "#vX_test = vectorizerLinear1.transform(X_tweetsTest)\n",
    "\n",
    "vX_train = vectorizerMLP1.fit_transform(X_tweetsTrain)\n",
    "vX_test = vectorizerMLP1.transform(X_tweetsTest)\n",
    "\n",
    "#vX_train = vectorizerNB1.fit_transform(X_tweetsTrain)\n",
    "#vX_test = vectorizerNB1.transform(X_tweetsTest)\n",
    "\n",
    "#vX_train = vectorizerDT_Kmeans_RF.fit_transform(X_tweetsTrain)\n",
    "#vX_test = vectorizerDT_Kmeans_RF.transform(X_tweetsTest)\n",
    "\n",
    "\n",
    "#vX_train = vectorizer.fit_transform(X_tweetsTrain)\n",
    "#vX_test = vectorizer.transform(X_tweetsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Seleccionar los emoticones que se encuentran dentro de un umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import emoji\n",
    "\n",
    "def obtenerNombreEmoji(stringDemojize):\n",
    "    separador= \":\"\n",
    "    occurrences = stringDemojize.count(separador)\n",
    "    indices = [i for i, a in enumerate(stringDemojize) if a == separador]\n",
    "    return stringDemojize[indices[0]+1 : indices[1]]\n",
    "\n",
    "def obtenerKEmojisMasUsadosTrain(threshold):\n",
    "    resEmojis = {}\n",
    "    contResEmojis = 0\n",
    "    colEmojisHombresCursor = db.emojis_hombres.find()\n",
    "    colPerfilMujeresCursor = db.emojis_mujeres.find()\n",
    "    colEmojisHombresCursorAux = colEmojisHombresCursor\n",
    "    colPerfilMujeresCursorAux = colPerfilMujeresCursor\n",
    "    datos_basicos = {}\n",
    "\n",
    "    for jsonEmoji in colEmojisHombresCursorAux:\n",
    "        for e in jsonEmoji['emojis']: \n",
    "            Nomemoji = obtenerNombreEmoji(emoji.demojize(e))\n",
    "            if(not (Nomemoji in datos_basicos)):\n",
    "                datos_basicos[Nomemoji] = 1\n",
    "            else:\n",
    "                datos_basicos[Nomemoji] = datos_basicos[Nomemoji] + 1\n",
    "\n",
    "    for jsonFoto in colPerfilMujeresCursorAux:\n",
    "        for  e in jsonEmoji['emojis']: \n",
    "            Nomemoji = obtenerNombreEmoji(emoji.demojize(e))\n",
    "            if(not (Nomemoji in datos_basicos)):\n",
    "                datos_basicos[Nomemoji] = 1\n",
    "            else:\n",
    "                datos_basicos[Nomemoji] = datos_basicos[Nomemoji] + 1\n",
    "    arregloTags = {}\n",
    "    \n",
    "    for k in datos_basicos:\n",
    "        if datos_basicos[k] > threshold:  \n",
    "            resEmojis[k] = contResEmojis\n",
    "            contResEmojis = contResEmojis + 1\n",
    "    return resEmojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar los tags de la foto de perfil que se encuentran dentro de un umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def obtenerKTagsMasUsadosTrain(threshold):\n",
    "    resTags = {}\n",
    "    contResTags = 0\n",
    "    colPerfilHombresCursor = db.foto_perfil_hombres.find()\n",
    "    colPerfilMujeresCursor = db.foto_perfil_mujeres.find()\n",
    "    colPerfilHombresCursorAux = colPerfilHombresCursor\n",
    "    colPerfilMujeresCursorAux = colPerfilMujeresCursor\n",
    "    datos_basicos = {}\n",
    "    for jsonFoto in colPerfilHombresCursorAux:\n",
    "        for t in jsonFoto['json_imagen']['tags']:\n",
    "            if(not (t['name'] in datos_basicos)):\n",
    "                datos_basicos[t['name']] = 1\n",
    "            else:\n",
    "                datos_basicos[t['name']] = datos_basicos[t['name']] + 1\n",
    "\n",
    "    for jsonFoto in colPerfilMujeresCursorAux:\n",
    "        for t in jsonFoto['json_imagen']['tags']:\n",
    "            if(not (t['name'] in datos_basicos)):\n",
    "                datos_basicos[t['name']] = 1\n",
    "            else:\n",
    "                datos_basicos[t['name']] = datos_basicos[t['name']] + 1\n",
    "    arregloTags = {}\n",
    "    \n",
    "    for k in datos_basicos:\n",
    "        if datos_basicos[k] > threshold:  \n",
    "            resTags[k] = contResTags\n",
    "            contResTags = contResTags + 1\n",
    "    return resTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Seleccionar las categorias de la foto de perfil que se encuentran dentro de un umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def obtenerKCatsMasUsadosTrain(threshold):\n",
    "    resCategories = {}\n",
    "    contResCats = 0\n",
    "    colPerfilHombresCursor = db.foto_perfil_hombres.find()\n",
    "    colPerfilMujeresCursor = db.foto_perfil_mujeres.find()\n",
    "    colPerfilHombresCursorAux = colPerfilHombresCursor\n",
    "    colPerfilMujeresCursorAux = colPerfilMujeresCursor\n",
    "    datos_basicos = {}\n",
    "    cont = 0\n",
    "    for jsonFoto in colPerfilHombresCursorAux:\n",
    "        try: \n",
    "            for t in jsonFoto['json_imagen']['categories']:\n",
    "                if(not (t['name'] in datos_basicos)):\n",
    "                    datos_basicos[t['name']] = 1\n",
    "                else:\n",
    "                    datos_basicos[t['name']] = datos_basicos[t['name']] + 1\n",
    "        except Exception as e:\n",
    "            cont = cont +1 \n",
    "            \n",
    "    for jsonFoto in colPerfilMujeresCursorAux:\n",
    "        try:\n",
    "            for t in jsonFoto['json_imagen']['categories']:\n",
    "                if(not (t['name'] in datos_basicos)):\n",
    "                    datos_basicos[t['name']] = 1\n",
    "                else:\n",
    "                    datos_basicos[t['name']] = datos_basicos[t['name']] + 1\n",
    "        except Exception as e:\n",
    "            cont = cont +1 \n",
    "\n",
    "            \n",
    "    for k in datos_basicos:\n",
    "        if datos_basicos[k] > threshold:  \n",
    "            resCategories[k] = contResCats\n",
    "            contResCats = contResCats + 1\n",
    "    return resCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setear valores para armar las matrices de emojis y de imagenes (con tags y cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Seleccionar las etiquetas y categorias a considerar\n",
    "tagsSeleccionadosTrain = obtenerKTagsMasUsadosTrain(0)\n",
    "catsSeleccionadosTrain = obtenerKCatsMasUsadosTrain(0)\n",
    "\n",
    "#Seleccionar los emoticones\n",
    "emojisSeleccionadosTrain = obtenerKEmojisMasUsadosTrain(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos las matrices de los emoticones y las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#IMAGENES\n",
    "matrizTagsTrain = np.zeros((len(US_train), len(tagsSeleccionadosTrain)))\n",
    "matrizTagsTest =  np.zeros((len(US_test), len(tagsSeleccionadosTrain)))\n",
    "\n",
    "matrizCatsTrain = np.zeros((len(US_train), len(catsSeleccionadosTrain)))\n",
    "matrizCatsTest =  np.zeros((len(US_test), len(catsSeleccionadosTrain)))\n",
    "\n",
    "#EMOTICONES\n",
    "matrizEmojisTrain = np.zeros((len(US_train), len(emojisSeleccionadosTrain)))\n",
    "matrizEmojisTest =  np.zeros((len(US_test), len(emojisSeleccionadosTrain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armar matrices imagen tags y cats + emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se buscan los emoticones de los usuarios que estan en los conjuntos US_train y US_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contFilaTrain = 0\n",
    "for us in US_train:\n",
    "    try:   \n",
    "        cursor = collEmojisHombres.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() == 0:\n",
    "            cursor = collEmojisMujeres.find({\"screen_name\":{\"$in\":[us]}})      \n",
    "        for jsonEmoji in cursor:\n",
    "            for e in jsonEmoji['emojis']: \n",
    "                nomemoji = obtenerNombreEmoji(emoji.demojize(e))\n",
    "                if(nomemoji in emojisSeleccionadosTrain):\n",
    "                    matrizEmojisTrain.itemset((contFilaTrain,emojisSeleccionadosTrain[nomemoji]),1) \n",
    "            contFilaTrain = contFilaTrain +1\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contFilaTest = 0\n",
    "\n",
    "for us in US_test:\n",
    "    try:   \n",
    "        cursor = collEmojisHombresNuestros.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() == 0:\n",
    "            cursor = collEmojisMujeresNuestros.find({\"screen_name\":{\"$in\":[us]}}) \n",
    "        for jsonEmoji in cursor:\n",
    "            for e in jsonEmoji['emojis']: \n",
    "                nomemoji = obtenerNombreEmoji(emoji.demojize(e))\n",
    "                print(nomemoji)\n",
    "                if(nomemoji in emojisSeleccionadosTrain):\n",
    "                    matrizEmojisTest.itemset((contFilaTest,emojisSeleccionadosTrain[nomemoji]),1) \n",
    "            contFilaTest = contFilaTest +1      \n",
    "    except Exception as e:\n",
    "        print(e)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Se buscan las etiquetas de las imagenes de los usuarios que estan en los conjuntos US_train y US_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yUs_train = vClasifUs\n",
    "yUs_test = y_vClasifTweetsTest\n",
    "\n",
    "y_vClasifImageTrain = yUs_train\n",
    "y_vClasifImageTest = yUs_test\n",
    "\n",
    "contFilaTrain = 0\n",
    "for us in US_train:\n",
    "    try:   \n",
    "        cursor = collFotoPerfilHombres.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() == 0:\n",
    "            cursor = collFotoPerfilMujeres.find({\"screen_name\":{\"$in\":[us]}})      \n",
    "        for s in cursor: \n",
    "            for t in s['json_imagen']['tags']:\n",
    "                if(t['name'] in tagsSeleccionadosTrain):\n",
    "                    matrizTagsTrain.itemset((contFilaTrain,tagsSeleccionadosTrain[t['name']]),1) \n",
    "            contFilaTrain = contFilaTrain +1\n",
    "                \n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contFilaTest = 0\n",
    "\n",
    "for us in US_test:\n",
    "    try:   \n",
    "        cursor = collFotoPerfilHombresNuestro.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() == 0:\n",
    "            cursor = collFotoPerfilMujeresNuestro.find({\"screen_name\":{\"$in\":[us]}})  \n",
    "        for s in cursor:\n",
    "            for t in s['json_imagen']['tags']:\n",
    "                if(t['name'] in tagsSeleccionadosTrain):\n",
    "                    matrizTagsTest.itemset((contFilaTest,tagsSeleccionadosTrain[t['name']]),1)\n",
    "            contFilaTest = contFilaTest +1      \n",
    "    except Exception as e:\n",
    "        print(e)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se buscan las cetegorias de las imagenes de los usuarios que estan en los conjuntos US_train y US_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_vClasifImageTrain = yUs_train\n",
    "y_vClasifImageTest = yUs_test\n",
    "\n",
    "contFilaTrain = 0\n",
    "for us in US_train:\n",
    "    try:   \n",
    "        cursor = collFotoPerfilHombres.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() == 0:\n",
    "            cursor = collFotoPerfilMujeres.find({\"screen_name\":{\"$in\":[us]}})      \n",
    "        for s in cursor: \n",
    "            for t in s['json_imagen']['categories']:\n",
    "                if(t['name'] in catsSeleccionadosTrain):\n",
    "                    matrizCatsTrain.itemset((contFilaTrain,catsSeleccionadosTrain[t['name']]),1)\n",
    "            contFilaTrain = contFilaTrain +1          \n",
    "    except Exception as e:\n",
    "        print(e)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contFilaTest = 0\n",
    "\n",
    "for us in US_test:\n",
    "    try:   \n",
    "        cursor = collFotoPerfilHombresNuestro.find({\"screen_name\":{\"$in\":[us]}})\n",
    "        if cursor.count() == 0:\n",
    "            cursor = collFotoPerfilMujeresNuestro.find({\"screen_name\":{\"$in\":[us]}})\n",
    "            if cursor.count() == 0:\n",
    "                print(us)\n",
    "        for s in cursor:\n",
    "            for t in s['json_imagen']['categories']:\n",
    "                if(t['name'] in catsSeleccionadosTrain):\n",
    "                    matrizCatsTest.itemset((contFilaTest,catsSeleccionadosTrain[t['name']]),1) #ver de obtener el confidence\n",
    "            contFilaTest = contFilaTest +1      \n",
    "    except Exception as e:\n",
    "        print(e)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concatenación de matrices - Armado de matriz final: Input para los clasificadores\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "c = sparse.hstack((vX_test, matrizCatsTest))\n",
    "vX_test = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = sparse.hstack((vX_test, matrizTagsTest))\n",
    "vX_test = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = sparse.hstack((vX_test, matrizEmojisTest))\n",
    "vX_test = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = sparse.hstack((vX_train, matrizCatsTrain))\n",
    "vX_train = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = sparse.hstack((vX_train, matrizTagsTrain))\n",
    "vX_train = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = sparse.hstack((vX_train, matrizEmojisTrain))\n",
    "vX_train = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para imprimir performance de un clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prediccion\n",
    "\n",
    "def performance_clasificador (vX_test, y_test, clf, avg, label): \n",
    "    yp = clf.predict(vX_test)\n",
    "    #Medida de Accuracy\n",
    "    print (\"Accuracy:\\t\\t\",metrics.accuracy_score(y_test,yp))\n",
    "    #Medida de Precision\n",
    "    print (\"Precision:\\t\\t\",metrics.precision_score(y_test,yp,average=avg, pos_label=label))\n",
    "    #Medida de Recall\n",
    "    print (\"Recall:\\t\\t\\t\",metrics.recall_score(y_test,yp,average=avg, pos_label=label))\n",
    "    #Medida F1\n",
    "    print (\"Medida F:\\t\\t\",metrics.f1_score(y_test,yp,average=avg, pos_label=label))  \n",
    "    #Matriz de Confusion\n",
    "    print (\"Matriz de Confusion:\\t\") \n",
    "    print (metrics.confusion_matrix(y_test,yp))\n",
    "    return       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clasificador LinearSVC ##Mejor Config\n",
    "t1=time.time()\n",
    "clf_svm = svm.LinearSVC(C=0.85,penalty='l2', loss='hinge',max_iter=40)\n",
    "clf_svm.fit(vX_train, yUs_train)\n",
    "t2=time.time()\n",
    "performance_clasificador (vX_test, yUs_test, clf_svm, 'binary', 0)\n",
    "performance_clasificador (vX_test, yUs_test, clf_svm, 'binary', 1)\n",
    "tfinal= t2 - t1\n",
    "print(tfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clasificador Naive Bayes ##Mejor Config\n",
    "t1=time.time()\n",
    "clf_NB = MultinomialNB(alpha=0.03).fit(vX_train, yUs_train)\n",
    "t2=time.time()\n",
    "performance_clasificador (vX_test, yUs_test, clf_NB, 'binary',0)\n",
    "performance_clasificador (vX_test, yUs_test, clf_NB, 'binary',1)\n",
    "tfinal= t2 - t1\n",
    "print(tfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clasificador Árbol Decisión ##Mejor Config\n",
    "t1=time.time()\n",
    "clf_DT = DecisionTreeClassifier(criterion='entropy', min_samples_split=1500).fit(vX_train, yUs_train)\n",
    "t2=time.time()\n",
    "performance_clasificador (vX_test, yUs_test, clf_DT, 'binary',0)\n",
    "performance_clasificador (vX_test, yUs_test, clf_DT, 'binary',1)\n",
    "tfinal= t2 - t1\n",
    "print(tfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clasificador RNA ##Mejor Config\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "t1=time.time()\n",
    "clf_NN = MLPClassifier(early_stopping=True, hidden_layer_sizes=(20,20)).fit(vX_train, yUs_train)\n",
    "t2=time.time()\n",
    "performance_clasificador (vX_test, yUs_test, clf_NN, 'binary',0)\n",
    "performance_clasificador (vX_test, yUs_test, clf_NN, 'binary',1)\n",
    "tfinal= t2 - t1\n",
    "print(tfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clasificador Clustering ##Mejor Config\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "t1=time.time()\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(vX_train)\n",
    "print(kmeans.labels_)\n",
    "t2=time.time()\n",
    "performance_clasificador (vX_test, yUs_test, kmeans, 'binary',0)\n",
    "performance_clasificador (vX_test, yUs_test, kmeans, 'binary',1)\n",
    "tfinal= t2 - t1\n",
    "print(tfinal)\n",
    "print (kmeans.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clasificador Bosuqe Aleatorios ##Mejor Config\n",
    "t1=time.time()\n",
    "clf = RandomForestClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=1500, min_weight_fraction_leaf=0.0,\n",
    "            random_state=None, n_jobs=-1,oob_score=True, warm_start=True).fit(vX_train, yUs_train)\n",
    "t2=time.time()\n",
    "performance_clasificador (vX_test, yUs_test, clf, 'binary',0)\n",
    "performance_clasificador (vX_test, yUs_test, clf, 'binary',1)\n",
    "tfinal= t2 - t1\n",
    "print(tfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Matriz de confusión para el mejor resultado: MLPClassifier\n",
    "yp = clf_NN.predict(vX_test)\n",
    "cm=metrics.confusion_matrix(yUs_test,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class_names =[0,1]\n",
    "class_names =['H','M']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names,\n",
    "                      title='Matriz de Confusión C4')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
